{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quiz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Que: Consider a data set that has 50 predictors and one continuous target variable. The target variable can take any positive value. Which of the following would be a suitable Neural Network architecture for such a data set?\n",
    "- One hidden layer with neurons having any activation function and one output layer with 3 neurons and softmax activation \n",
    "- One hidden layer with neurons having any activation function and one output layer with one neuron having linear activation \n",
    "- One hidden layer with neurons having any activation function and one output layer with one neuron having relu activation \n",
    "- One hidden layer with neurons having any activation function and one output layer with one neuron having sigmoid activation \n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Que: When a multiclass neural network classifier is built, the activation function used in the output layer is always:\n",
    "- Softmax \n",
    "- Relu \n",
    "- Tanh \n",
    "- Sigmoid "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Que: Do convolutional neural networks contain fully connected layers?\n",
    "- Yes \n",
    "- No "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Que: In the context of neural network training, an epoch is:\n",
    "- A complete forward and backward pass on whole data set, once \n",
    "- A complete forward pass on whole data set \n",
    "- A complete backward pass on whole data set \n",
    "- Total Data set divided by batch size "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Que: In a convolutional neural network, a pooling layer:\n",
    "\n",
    "- Decreases the size of the input images passed \n",
    "- Increase the size of the input images passed \n",
    "- Doesnâ€™t change the size of the input image passed \n",
    "- Extracts meaningful features out of images "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Que: In a convolutional neural network, the input to the network:\n",
    "- Can be an image matrix of pixel values \n",
    "- Can be only a flattened vector of image matrix \n",
    "- Can be only a 1 dimensional array "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Que: When a neural network is trained, in a backward pass:\n",
    "\n",
    "- The cost function is maximised \n",
    "- The weights of neural network get updated \n",
    "- A prediction on data is made \n",
    "- Activations across neurons in different layers is computed "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Que: A convolutional layer in a convolutional neural network is used to:\n",
    "- Extract meaningful features out of images \n",
    "- Flatten the images \n",
    "- Convert the images into grey scale \n",
    "- Normalise the pixel values between 0 to 1 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Que: Will a sigmoid activation function be a good choice for the output layer of a Multi Layered Perceptron regressor?\n",
    "- Yes \n",
    "- No "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Que: Neural Networks can only be used to do classification tasks?\n",
    "- True \n",
    "- False "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Case Study- Ans all the Questions\n",
    "Image Classification\n",
    "\n",
    "Use the data in the compressed file named, Data.7z (this is a compressed file, you will need to uncompress it with a utility such as 7 zip). Once you extract the file, you will get access to 1 folder, train. This folder contains, subfolders with images of handwritten devnagri characters and digits. Your task is to build a CNN based image classifier, which will be able to distinguish between different handwritten devnagri characters. The first thing that you need to do is, read all the images in the train folder and build a model. To read images make use of opencv3."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 1\n",
    "Q1. Before building the image classifier, you will need do some data munging. You will need to understand your data first. Keeping this context in mind, answer the questions raised below\n",
    "\n",
    "(a) In the train folder, images of how many different classes are present? (Hint: use os module)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46 folders or classes\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "path = r\"C:\\Users\\ABC\\Documents\\IBM AI 6th sem\\2. Deep Learning\\11. CNN 13-03\\17 CNN Based Case Study\\Data\\Train\"\n",
    "files = folders = 0\n",
    "count_images = []\n",
    "for _, dirnames, filenames in os.walk(path):\n",
    "\n",
    "    files += len(filenames)\n",
    "    folders += len(dirnames)\n",
    "    count_images.append(len(filenames))\n",
    "\n",
    "print(folders ,\"folders or classes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q1. Before building the image classifier, you will need do some data munging. You will need to understand your data first. Keeping this context in mind, answer the questions raised below\n",
    "\n",
    "(b) How many total images are present in the train folder? (Hint: use os module)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "78200 files or images\n"
     ]
    }
   ],
   "source": [
    "print(files ,\"files or images\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q1. Before building the image classifier, you will need do some data munging. You will need to understand your data first. Keeping this context in mind, answer the questions raised below\n",
    "\n",
    "(c) Read all the images (in the train folder) and their associated labels in to two separate lists. While reading the images make sure that, images are in grayscale colorspace (use opencv to achieve this). Do all the images have a dimension of 28 by 28 pixels.\n",
    "\n",
    "(Hint: use os and opencv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import glob\n",
    "\n",
    "folders = glob.glob(r'C:\\Users\\ABC\\Documents\\IBM AI 6th sem\\2. Deep Learning\\11. CNN 13-03\\17 CNN Based Case Study\\Data\\Train\\*')\n",
    "imagenames_list = []\n",
    "\n",
    "for folder in folders:\n",
    "    for f in glob.glob(folder+'/*.*'):\n",
    "        imagenames_list.append(f)\n",
    "\n",
    "read_images = []\n",
    "for image in imagenames_list:\n",
    "    read_images.append(cv2.imread(image, cv2.IMREAD_GRAYSCALE))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\ABC\\\\Documents\\\\IBM AI 6th sem\\\\2. Deep Learning\\\\11. CNN 13-03\\\\17 CNN Based Case Study\\\\Data\\\\Train\\\\character_10_yna\\\\137.png'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imagenames_list[100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "78200"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(read_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = np.array(read_images,dtype='float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(78200, 32, 32)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q1. Before building the image classifier, you will need do some data munging. You will need to understand your data first. Keeping this context in mind, answer the questions raised below\n",
    "\n",
    "(d) If you flatten all the images (in the train folder) and create a dataframe, with each row of the dataframe representing a flattened image, then, how many columns this dataframe will have?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = np.reshape(images,(-1,1024))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(78200, 1024)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RangeIndex(start=0, stop=1024, step=1)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df1 = pd.DataFrame(df)\n",
    "df1.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q1. Before building the image classifier, you will need do some data munging. You will need to understand your data first. Keeping this context in mind, answer the questions raised below\n",
    "\n",
    "(e) How many images are there per class in train data. (Each folder inside train contains images corresponding to specific devnagri alphabets or digits)\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_images.remove(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1700, 1700, 1700, 1700, 1700, 1700, 1700, 1700, 1700, 1700, 1700,\n",
       "       1700, 1700, 1700, 1700, 1700, 1700, 1700, 1700, 1700, 1700, 1700,\n",
       "       1700, 1700, 1700, 1700, 1700, 1700, 1700, 1700, 1700, 1700, 1700,\n",
       "       1700, 1700, 1700, 1700, 1700, 1700, 1700, 1700, 1700, 1700, 1700,\n",
       "       1700, 1700])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.array(count_images) # Number of images folder wise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q2. You now will need to build an image classifier. Use a CNN architecture to build an image classifier. Use the train data to get a model. Then use the test_X.csv to make predictions. This file contains, flattened images of devnagri characters. The images in test_X.csv are of same dimensions as images in train folder, hence when you will reshape these images, you will get images with same dimensions as the ones you used to train the model. You need to make predictions on the test_X.csv. Make sure that your predictions are in the same format as given in the file submission_format.xlsx. Essentially you need to predict the class of each image in test data. Make sure the labels are spelt the same way as they are in the train data or as suggested by submission_format.xlsx (names of sub-folders in train data).\n",
    "\n",
    " \n",
    "\n",
    "(a) Submit your python script here (Formats accepted, .html)\n",
    "\n",
    " \n",
    "\n",
    "To download python script as html from jupyter notebook. Follow below steps\n",
    "File -> Download as -> html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q2. You now will need to build an image classifier. Use a CNN architecture to build an image classifier. Use the train data to get a model. Then use the test_X.csv to make predictions. This file contains, flattened images of devnagri characters. The images in test_X.csv are of same dimensions as images in train folder, hence when you will reshape these images, you will get images with same dimensions as the ones you used to train the model. You need to make predictions on the test_X.csv. Make sure that your predictions are in the same format as given in the file submission_format.xlsx. Essentially you need to predict the class of each image in test data. Make sure the labels are spelt the same way as they are in the train data or as suggested by submission_format.xlsx (names of sub-folders in train data).\n",
    "\n",
    "(b) Submit your predictions (name your file as pred.csv, make sure it is in the correct format, as suggested above)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
