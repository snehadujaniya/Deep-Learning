{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = r\"C:\\Users\\ABC\\Documents\\IBM AI 6th sem\\2. Deep Learning\\16 Case Study Based on Deep Learning\\final_data\"\n",
    "image_names = []\n",
    "for img in glob.glob(path + '/*.*'):\n",
    "    image_names.append(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "47"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(image_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.image import load_img, img_to_array\n",
    "from keras.applications.vgg16 import VGG16, preprocess_input, decode_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"vgg16\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 224, 224, 3)       0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 25088)             0         \n",
      "_________________________________________________________________\n",
      "fc1 (Dense)                  (None, 4096)              102764544 \n",
      "_________________________________________________________________\n",
      "fc2 (Dense)                  (None, 4096)              16781312  \n",
      "_________________________________________________________________\n",
      "predictions (Dense)          (None, 1000)              4097000   \n",
      "=================================================================\n",
      "Total params: 138,357,544\n",
      "Trainable params: 138,357,544\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = VGG16()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing image and decoding the prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoded_predictions = []\n",
    "def preprocess_img(image_names):\n",
    "    for image in image_names:\n",
    "        img = load_img(image, target_size=(224,224))\n",
    "        img_array = img_to_array(img)\n",
    "        img_array = np.expand_dims(img_array, axis=0)\n",
    "        img_preprocessed = preprocess_input(img_array)\n",
    "        pred = model.predict(img_preprocessed)\n",
    "        p = decode_predictions(pred,top=1)\n",
    "        decoded_predictions.append(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocess_img(image_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[[('n03642806', 'laptop', 0.5207487)]],\n",
       " [[('n04536866', 'violin', 0.2565639)]],\n",
       " [[('n02085620', 'Chihuahua', 0.7262916)]],\n",
       " [[('n02690373', 'airliner', 0.96722454)]],\n",
       " [[('n02106662', 'German_shepherd', 0.9561889)]],\n",
       " [[('n03642806', 'laptop', 0.20732011)]],\n",
       " [[('n04536866', 'violin', 0.15532602)]],\n",
       " [[('n02106662', 'German_shepherd', 0.5546458)]],\n",
       " [[('n03028079', 'church', 0.77817565)]],\n",
       " [[('n02106662', 'German_shepherd', 0.92137504)]],\n",
       " [[('n02123045', 'tabby', 0.49881372)]],\n",
       " [[('n02123045', 'tabby', 0.48484927)]],\n",
       " [[('n04536866', 'violin', 0.4312015)]],\n",
       " [[('n02123045', 'tabby', 0.83191854)]],\n",
       " [[('n03028079', 'church', 0.7882353)]],\n",
       " [[('n04536866', 'violin', 0.9153487)]],\n",
       " [[('n02106662', 'German_shepherd', 0.7093517)]],\n",
       " [[('n03028079', 'church', 0.41351193)]],\n",
       " [[('n02085620', 'Chihuahua', 0.982643)]],\n",
       " [[('n02106662', 'German_shepherd', 0.992246)]],\n",
       " [[('n03642806', 'laptop', 0.5367554)]],\n",
       " [[('n02437312', 'Arabian_camel', 0.9999763)]],\n",
       " [[('n04536866', 'violin', 0.5818773)]],\n",
       " [[('n04536866', 'violin', 0.5038742)]],\n",
       " [[('n03028079', 'church', 0.74379325)]],\n",
       " [[('n04536866', 'violin', 0.13302112)]],\n",
       " [[('n03028079', 'church', 0.6216692)]],\n",
       " [[('n02676566', 'acoustic_guitar', 0.3655365)]],\n",
       " [[('n03028079', 'church', 0.779567)]],\n",
       " [[('n02106662', 'German_shepherd', 0.66354)]],\n",
       " [[('n04536866', 'violin', 0.865271)]],\n",
       " [[('n02123045', 'tabby', 0.344693)]],\n",
       " [[('n04536866', 'violin', 0.85799974)]],\n",
       " [[('n02106662', 'German_shepherd', 0.8092185)]],\n",
       " [[('n02437312', 'Arabian_camel', 0.9999982)]],\n",
       " [[('n04536866', 'violin', 0.98859894)]],\n",
       " [[('n04536866', 'violin', 0.9860865)]],\n",
       " [[('n02123045', 'tabby', 0.4067901)]],\n",
       " [[('n04536866', 'violin', 0.9569923)]],\n",
       " [[('n04536866', 'violin', 0.6022896)]],\n",
       " [[('n02085620', 'Chihuahua', 0.86679816)]],\n",
       " [[('n04536866', 'violin', 0.56526124)]],\n",
       " [[('n03028079', 'church', 0.36685222)]],\n",
       " [[('n03028079', 'church', 0.33721203)]],\n",
       " [[('n03642806', 'laptop', 0.41952544)]],\n",
       " [[('n02085620', 'Chihuahua', 0.5460984)]],\n",
       " [[('n02123045', 'tabby', 0.60808635)]]]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoded_predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reducing the shape of decoded predictions for mapping with the image names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(47, 1, 1, 3)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(decoded_predictions).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Chihuahua'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoded_predictions[2][0][0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoded_predictions2 = [decoded_predictions[i][0][0][1] for i in range(0,len(image_names))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['laptop',\n",
       " 'violin',\n",
       " 'Chihuahua',\n",
       " 'airliner',\n",
       " 'German_shepherd',\n",
       " 'laptop',\n",
       " 'violin',\n",
       " 'German_shepherd',\n",
       " 'church',\n",
       " 'German_shepherd',\n",
       " 'tabby',\n",
       " 'tabby',\n",
       " 'violin',\n",
       " 'tabby',\n",
       " 'church',\n",
       " 'violin',\n",
       " 'German_shepherd',\n",
       " 'church',\n",
       " 'Chihuahua',\n",
       " 'German_shepherd',\n",
       " 'laptop',\n",
       " 'Arabian_camel',\n",
       " 'violin',\n",
       " 'violin',\n",
       " 'church',\n",
       " 'violin',\n",
       " 'church',\n",
       " 'acoustic_guitar',\n",
       " 'church',\n",
       " 'German_shepherd',\n",
       " 'violin',\n",
       " 'tabby',\n",
       " 'violin',\n",
       " 'German_shepherd',\n",
       " 'Arabian_camel',\n",
       " 'violin',\n",
       " 'violin',\n",
       " 'tabby',\n",
       " 'violin',\n",
       " 'violin',\n",
       " 'Chihuahua',\n",
       " 'violin',\n",
       " 'church',\n",
       " 'church',\n",
       " 'laptop',\n",
       " 'Chihuahua',\n",
       " 'tabby']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoded_predictions2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\ABC\\\\Documents\\\\IBM AI 6th sem\\\\2. Deep Learning\\\\16 Case Study Based on Deep Learning\\\\final_data'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['109443289_b3edb30465_o.jpg',\n",
       " '109877767_ff8f921b95_o.jpg',\n",
       " '112568527_4afd965e6d_o.jpg',\n",
       " '1322285840_13371404fb_o.jpg',\n",
       " '145039929_c699b8f866_o.jpg',\n",
       " '155096186_4fdfed77c9_o.jpg',\n",
       " '160570428_2040c5298b_o.jpg',\n",
       " '211079993_c9e9a3508d_o.jpg',\n",
       " '211962450_317eda6dbc_o.jpg',\n",
       " '224039495_a0713c10d4_o.jpg',\n",
       " '2339481262_9b28130275_o.jpg',\n",
       " '2344176829_7df1d61e13_o.jpg',\n",
       " '238399657_2cab047e27_o.jpg',\n",
       " '2401371232_55b19d7faf_o.jpg',\n",
       " '2412484421_151951684a_o.jpg',\n",
       " '2417256829_886bf41e29_o.jpg',\n",
       " '268281342_2117a41a98_o.jpg',\n",
       " '306864929_c7a5351ebb_o.jpg',\n",
       " '332070599_1eef2b4ef9_o.jpg',\n",
       " '33518818093_e1cb903449_o.jpg',\n",
       " '338682343_53377501fc_o.jpg',\n",
       " '33996916835_b10f6e2ddd_o.jpg',\n",
       " '34442615_d709d1a2e0_o.jpg',\n",
       " '36156629280_1bc82041c9_o.jpg',\n",
       " '36314552682_476e854e6c_o.jpg',\n",
       " '36511950852_12385140c4_o.jpg',\n",
       " '37109776043_fb86431426_o.jpg',\n",
       " '37124855575_f102cf470c_o.jpg',\n",
       " '38067783776_f4b85f2697_o.jpg',\n",
       " '383986829_65a6911ce9_o.jpg',\n",
       " '3862575456_89084ce644_o.jpg',\n",
       " '38851691005_a7a46705a3_o.jpg',\n",
       " '3963017378_e07e93ef2b_o.jpg',\n",
       " '3970268741_d264cfa0ae_o.jpg',\n",
       " '3971801573_4393163307_o.jpg',\n",
       " '3986717665_b75a7b54b5_o.jpg',\n",
       " '4020061139_683f3c7e17_o.jpg',\n",
       " '40412184490_e5ab6bc35c_o.jpg',\n",
       " '4045054988_a6d7519ebc_o.jpg',\n",
       " '40651833692_320e1f7fe1_o.jpg',\n",
       " '4111963443_00a8a07a0f_o.jpg',\n",
       " '4112317638_37aed2a802_o.jpg',\n",
       " '475252798_beb7334443_o.jpg',\n",
       " '479707595_92cc963671_o.jpg',\n",
       " '52062370_6ea54397d1_o.jpg',\n",
       " '60113299_f80aca1d24_o.jpg',\n",
       " '96380377_0c42619ac8_o.jpg']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images = os.listdir(path)\n",
    "images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'109443289_b3edb30465_o.jpg': 'laptop',\n",
       " '109877767_ff8f921b95_o.jpg': 'violin',\n",
       " '112568527_4afd965e6d_o.jpg': 'Chihuahua',\n",
       " '1322285840_13371404fb_o.jpg': 'airliner',\n",
       " '145039929_c699b8f866_o.jpg': 'German_shepherd',\n",
       " '155096186_4fdfed77c9_o.jpg': 'laptop',\n",
       " '160570428_2040c5298b_o.jpg': 'violin',\n",
       " '211079993_c9e9a3508d_o.jpg': 'German_shepherd',\n",
       " '211962450_317eda6dbc_o.jpg': 'church',\n",
       " '224039495_a0713c10d4_o.jpg': 'German_shepherd',\n",
       " '2339481262_9b28130275_o.jpg': 'tabby',\n",
       " '2344176829_7df1d61e13_o.jpg': 'tabby',\n",
       " '238399657_2cab047e27_o.jpg': 'violin',\n",
       " '2401371232_55b19d7faf_o.jpg': 'tabby',\n",
       " '2412484421_151951684a_o.jpg': 'church',\n",
       " '2417256829_886bf41e29_o.jpg': 'violin',\n",
       " '268281342_2117a41a98_o.jpg': 'German_shepherd',\n",
       " '306864929_c7a5351ebb_o.jpg': 'church',\n",
       " '332070599_1eef2b4ef9_o.jpg': 'Chihuahua',\n",
       " '33518818093_e1cb903449_o.jpg': 'German_shepherd',\n",
       " '338682343_53377501fc_o.jpg': 'laptop',\n",
       " '33996916835_b10f6e2ddd_o.jpg': 'Arabian_camel',\n",
       " '34442615_d709d1a2e0_o.jpg': 'violin',\n",
       " '36156629280_1bc82041c9_o.jpg': 'violin',\n",
       " '36314552682_476e854e6c_o.jpg': 'church',\n",
       " '36511950852_12385140c4_o.jpg': 'violin',\n",
       " '37109776043_fb86431426_o.jpg': 'church',\n",
       " '37124855575_f102cf470c_o.jpg': 'acoustic_guitar',\n",
       " '38067783776_f4b85f2697_o.jpg': 'church',\n",
       " '383986829_65a6911ce9_o.jpg': 'German_shepherd',\n",
       " '3862575456_89084ce644_o.jpg': 'violin',\n",
       " '38851691005_a7a46705a3_o.jpg': 'tabby',\n",
       " '3963017378_e07e93ef2b_o.jpg': 'violin',\n",
       " '3970268741_d264cfa0ae_o.jpg': 'German_shepherd',\n",
       " '3971801573_4393163307_o.jpg': 'Arabian_camel',\n",
       " '3986717665_b75a7b54b5_o.jpg': 'violin',\n",
       " '4020061139_683f3c7e17_o.jpg': 'violin',\n",
       " '40412184490_e5ab6bc35c_o.jpg': 'tabby',\n",
       " '4045054988_a6d7519ebc_o.jpg': 'violin',\n",
       " '40651833692_320e1f7fe1_o.jpg': 'violin',\n",
       " '4111963443_00a8a07a0f_o.jpg': 'Chihuahua',\n",
       " '4112317638_37aed2a802_o.jpg': 'violin',\n",
       " '475252798_beb7334443_o.jpg': 'church',\n",
       " '479707595_92cc963671_o.jpg': 'church',\n",
       " '52062370_6ea54397d1_o.jpg': 'laptop',\n",
       " '60113299_f80aca1d24_o.jpg': 'Chihuahua',\n",
       " '96380377_0c42619ac8_o.jpg': 'tabby'}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i in range(0,len(image_names)):\n",
    "    mapped_values = dict(zip(images,decoded_predictions2))\n",
    "mapped_values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving the csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "path = r\"C:\\Users\\ABC\\Documents\\IBM AI 6th sem\\2. Deep Learning\\16 Case Study Based on Deep Learning\"\n",
    "with open(os.path.join(path,'submission_file.csv'), 'w') as f:\n",
    "    for key in mapped_values.keys():\n",
    "        f.write(\"%s,%s\\n\"%(mapped_values[key],key))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Making folders as required"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['laptop',\n",
       " 'violin',\n",
       " 'Chihuahua',\n",
       " 'airliner',\n",
       " 'German_shepherd',\n",
       " 'church',\n",
       " 'tabby',\n",
       " 'Arabian_camel',\n",
       " 'acoustic_guitar']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(decoded_predictions2)[0].unique()\n",
    "category = df.tolist()\n",
    "category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['acoustic_guitar',\n",
       " 'airliner',\n",
       " 'arabian_camel',\n",
       " 'chihuahua',\n",
       " 'church',\n",
       " 'german_shepherd',\n",
       " 'laptop',\n",
       " 'tabby',\n",
       " 'violin']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i in range(0,len(category)):\n",
    "    category[i] = category[i].lower()\n",
    "\n",
    "category.sort()\n",
    "category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_names = [\"acoustic\",\"airliner\",\"arabian\",\"chihuahua\",\"church\",\"german\",\"laptop\",\"tabby\",\"violin\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "num = [*range(0,9,1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_name_dict = dict(zip(num,folder_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'acoustic',\n",
       " 1: 'airliner',\n",
       " 2: 'arabian',\n",
       " 3: 'chihuahua',\n",
       " 4: 'church',\n",
       " 5: 'german',\n",
       " 6: 'laptop',\n",
       " 7: 'tabby',\n",
       " 8: 'violin'}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "folder_name_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "path2 = r\"C:\\Users\\ABC\\Documents\\IBM AI 6th sem\\2. Deep Learning\\16 Case Study Based on Deep Learning\"\n",
    "for i in folder_names:\n",
    "    os.mkdir(os.path.join(path2,i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_values(['laptop', 'violin', 'Chihuahua', 'airliner', 'German_shepherd', 'laptop', 'violin', 'German_shepherd', 'church', 'German_shepherd', 'tabby', 'tabby', 'violin', 'tabby', 'church', 'violin', 'German_shepherd', 'church', 'Chihuahua', 'German_shepherd', 'laptop', 'Arabian_camel', 'violin', 'violin', 'church', 'violin', 'church', 'acoustic_guitar', 'church', 'German_shepherd', 'violin', 'tabby', 'violin', 'German_shepherd', 'Arabian_camel', 'violin', 'violin', 'tabby', 'violin', 'violin', 'Chihuahua', 'violin', 'church', 'church', 'laptop', 'Chihuahua', 'tabby'])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mapped_values.values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "j=0\n",
    "for i in mapped_values.values():\n",
    "    index = category.index(i.lower())\n",
    "    img = cv2.imread(image_names[j],1)\n",
    "    os.chdir(os.path.join(path)+'\\\\'+folder_name_dict[index])\n",
    "    name = images[j]\n",
    "    cv2.imwrite(name,img)\n",
    "    cv2.waitKey(0)\n",
    "    j+=1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
